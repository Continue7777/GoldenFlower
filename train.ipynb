{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From DQN.py:96: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "DQN.py:149: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if action_index not in availble_actions:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss', 100, 85.90619)\n",
      "episode 10000\n",
      "('loss', 200, 75.87521)\n",
      "episode 20000\n",
      "('loss', 300, 81.20457)\n",
      "episode 30000\n",
      "episode 30000\n",
      "('loss', 400, 95.88106)\n",
      "episode 40000\n",
      "episode 40000\n",
      "episode 40000\n",
      "('loss', 500, 104.50111)\n",
      "('loss', 600, 66.29911)\n",
      "episode 50000\n",
      "episode 50000\n",
      "episode 50000\n",
      "('loss', 700, 115.61976)\n",
      "episode 60000\n",
      "('loss', 800, 109.79851)\n",
      "('loss', 900, 91.02393)\n",
      "episode 70000\n",
      "episode 70000\n",
      "('loss', 1000, 81.107346)\n",
      "episode 80000\n",
      "('loss', 1100, 85.606766)\n",
      "episode 90000\n",
      "episode 90000\n",
      "('loss', 1200, 100.627785)\n",
      "('loss', 1300, 96.24274)\n",
      "episode 100000\n",
      "('loss', 1400, 102.49254)\n",
      "episode 110000\n",
      "('loss', 1500, 79.0897)\n",
      "episode 120000\n",
      "('loss', 1600, 125.731346)\n",
      "('loss', 1700, 85.38411)\n",
      "episode 130000\n",
      "('loss', 1800, 83.984245)\n",
      "('loss', 1900, 104.477165)\n",
      "episode 150000\n",
      "episode 150000\n",
      "('loss', 2000, 64.22027)\n",
      "('loss', 2100, 76.53368)\n",
      "('loss', 2200, 88.08682)\n",
      "episode 170000\n",
      "('loss', 2300, 113.84502)\n",
      "('loss', 2400, 97.78568)\n",
      "episode 180000\n",
      "episode 180000\n",
      "('loss', 2500, 78.586975)\n",
      "episode 190000\n",
      "episode 190000\n",
      "episode 190000\n",
      "('loss', 2600, 85.92421)\n",
      "episode 200000\n",
      "('loss', 2700, 132.64723)\n",
      "episode 210000\n",
      "('loss', 2800, 87.13909)\n",
      "('loss', 2900, 93.700386)\n",
      "('loss', 3000, 93.6196)\n",
      "episode 230000\n",
      "episode 230000\n",
      "('loss', 3100, 110.002754)\n",
      "('loss', 3200, 109.736465)\n",
      "episode 240000\n",
      "episode 240000\n",
      "('loss', 3300, 99.384415)\n",
      "episode 250000\n",
      "('loss', 3400, 156.08522)\n",
      "episode 260000\n",
      "('loss', 3500, 91.76032)\n",
      "('loss', 3600, 89.688705)\n",
      "('loss', 3700, 117.58976)\n",
      "episode 280000\n",
      "('loss', 3800, 104.14965)\n",
      "episode 290000\n",
      "episode 290000\n",
      "('loss', 3900, 98.811295)\n",
      "('loss', 4000, 91.43261)\n",
      "episode 300000\n",
      "episode 300000\n",
      "episode 300000\n",
      "('loss', 4100, 97.455215)\n",
      "episode 310000\n",
      "('loss', 4200, 83.67774)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cce324dbcf2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# DQN 根据观测值选择行为\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mavailble_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgameEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchooseAvailbleAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayerI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRLModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobservation_this\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavailble_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# 环境根据行为给出下一个 state, reward, 是否终止\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print (playerI, action, gameEnv.deskMoney, gameEnv.nowPrice,gameEnv.personStatus[playerI])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/opt/jupyter/fanyu.zhang/GoldenFlower/DQN.pyc\u001b[0m in \u001b[0;36mchoose_action\u001b[0;34m(self, status, availble_actions)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavailble_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#通过训练好的网络，根据状态获取动作\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0maction_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_max_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction_index\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavailble_actions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavailble_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/opt/jupyter/fanyu.zhang/GoldenFlower/DQN.pyc\u001b[0m in \u001b[0;36mget_max_action\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_max_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictionsMaxQAction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#通过训练好的网络，根据状态获取动作\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8\n",
    "import sys\n",
    "stdi, stdo, stde = sys.stdin, sys.stdout, sys.stderr\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdin, sys.stdout, sys.stderr = stdi, stdo, stde\n",
    "\n",
    "import GameEnv\n",
    "import random\n",
    "import numpy as np\n",
    "import DQN\n",
    "\n",
    "gameEnv = GameEnv.GlodenFlower([20000,20000])\n",
    "RLModel = DQN.DQN(embedding_size=10,sequence_length=20,learning_rate=0.1,batch_size=500)\n",
    "gameEnv.debug = False\n",
    "memory = []\n",
    "for episode in range(500000):\n",
    "    # 初始化环境\n",
    "    gameEnv.reset()\n",
    "\n",
    "    playerI = gameEnv.getStartTurn()\n",
    "    observation_this = [[],gameEnv.playerCards[\"A\"],gameEnv.personStatus[\"A\"]]\n",
    "    if playerI == \"B\":\n",
    "        availble_actions = gameEnv.chooseAvailbleAction(playerI)\n",
    "        action = RLModel.choose_action(np.array([observation_this]),availble_actions)\n",
    "        #print (playerI, action, gameEnv.deskMoney, gameEnv.nowPrice)\n",
    "        observation_next, reward, done = gameEnv.step(action, \"B\")\n",
    "        playerI = \"A\"\n",
    "        if done:\n",
    "            continue\n",
    "\n",
    "    while True:\n",
    "        # DQN 根据观测值选择行为\n",
    "        availble_actions = gameEnv.chooseAvailbleAction(playerI)\n",
    "        action = RLModel.choose_action(np.array([observation_this]),availble_actions)\n",
    "        # 环境根据行为给出下一个 state, reward, 是否终止\n",
    "        #print (playerI, action, gameEnv.deskMoney, gameEnv.nowPrice,gameEnv.personStatus[playerI])\n",
    "        observation_next, reward, done = gameEnv.stepA(action,RLModel)\n",
    "\n",
    "\n",
    "        # DQN 存储记忆\n",
    "        # RL.store_transition(observation, action, reward)\n",
    "        RLModel.store_transition(observation_this, action, reward,done,observation_next)\n",
    "\n",
    "        # 控制学习起始时间和频率 (先累积一些记忆再开始学习)\n",
    "        if (episode > 2000) and (episode % 100 == 0):\n",
    "            if episode % 10000 == 0 :print \"episode\",episode\n",
    "            RLModel.train()\n",
    "\n",
    "        # 将下一个 state_ 变为 下次循环的 state\n",
    "        observation_this = observation_next\n",
    "\n",
    "        # 如果终止, 就跳出循环\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        # end of game\n",
    "print('game over')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 闷_2 0.0\n",
      "1 闷_4 0.0\n",
      "2 闷_8 0.0\n",
      "3 闷开_0 0.0\n",
      "4 看_2 2.6749284\n",
      "5 看_5 2.5375712\n",
      "6 看_10 2.2168646\n",
      "7 看_20 1.5940257\n",
      "8 开_0 -7.2232695\n",
      "9 丢_0 -7.316115\n"
     ]
    }
   ],
   "source": [
    "res = RLModel.sess.run(RLModel.predictions,feed_dict=RLModel._feed_dict(np.array([[[\"A_看_5\", \"B_看_5\", \"A_看_5\", \"B_看_20\"], ['diamond_7', 'heart_7', 'spade_7'],\"看\"]])))\n",
    "for i,v in  zip(RLModel.action_reverse_index_dicts.keys(),res[0]):\n",
    "    print i, RLModel.action_reverse_index_dicts[i],v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 闷_2 0.8323411\n",
      "1 闷_4 0.80202866\n",
      "2 闷_8 0.31619662\n",
      "3 闷开_0 0.66839844\n",
      "4 看_2 0.0\n",
      "5 看_5 0.0\n",
      "6 看_10 0.0\n",
      "7 看_20 0.0\n",
      "8 开_0 -0.0\n",
      "9 丢_0 -0.0\n"
     ]
    }
   ],
   "source": [
    "res = RLModel.sess.run(RLModel.predictions,feed_dict=RLModel._feed_dict(np.array([[[\"A_闷_8\", \"B_闷_8\", \"A_闷_8\", \"B_看_20\"], ['diamond_7', 'heart_7', 'spade_7'],\"闷\"]])))\n",
    "for i,v in  zip(RLModel.action_reverse_index_dicts.keys(),res[0]):\n",
    "    print i, RLModel.action_reverse_index_dicts[i],v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 闷_2 0.0\n",
      "1 闷_4 0.0\n",
      "2 闷_8 0.0\n",
      "3 闷开_0 0.0\n",
      "4 看_2 1.7622914\n",
      "5 看_5 1.1329337\n",
      "6 看_10 1.0658267\n",
      "7 看_20 0.98763716\n",
      "8 开_0 -3.502627\n",
      "9 丢_0 -3.6997738\n"
     ]
    }
   ],
   "source": [
    "res = RLModel.sess.run(RLModel.predictions,feed_dict=RLModel._feed_dict(np.array([[[], ['diamond_2', 'heart_2', 'spade_2'],\"看\"]])))\n",
    "for i,v in  zip(RLModel.action_reverse_index_dicts.keys(),res[0]):\n",
    "    print i, RLModel.action_reverse_index_dicts[i],v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 闷_2 0.0\n",
      "1 闷_4 0.0\n",
      "2 闷_8 0.0\n",
      "3 闷开_0 0.0\n",
      "4 看_2 0.8531427\n",
      "5 看_5 2.3518207\n",
      "6 看_10 1.4212455\n",
      "7 看_20 2.0196583\n",
      "8 开_0 -1.1234959\n",
      "9 丢_0 -4.4069185\n"
     ]
    }
   ],
   "source": [
    "res = RLModel.sess.run(RLModel.predictions,feed_dict=RLModel._feed_dict(np.array([[[], ['diamond_4', 'heart_5', 'spade_2'],\"看\"]])))\n",
    "for i,v in  zip(RLModel.action_reverse_index_dicts.keys(),res[0]):\n",
    "    print i, RLModel.action_reverse_index_dicts[i],v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 闷_2 0.95227855\n",
      "1 闷_4 1.1853846\n",
      "2 闷_8 0.81203157\n",
      "3 闷开_0 0.95211285\n",
      "4 看_2 0.0\n",
      "5 看_5 0.0\n",
      "6 看_10 0.0\n",
      "7 看_20 0.0\n",
      "8 开_0 -0.0\n",
      "9 丢_0 -0.0\n"
     ]
    }
   ],
   "source": [
    "res = RLModel.sess.run(RLModel.predictions,feed_dict=RLModel._feed_dict(np.array([[[], ['diamond_1', 'heart_5', 'spade_2'],\"闷\"]])))\n",
    "for i,v in  zip(RLModel.action_reverse_index_dicts.keys(),res[0]):\n",
    "    print i, RLModel.action_reverse_index_dicts[i],v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 闷_2 1.29885\n",
      "1 闷_4 1.3534505\n",
      "2 闷_8 0.9347714\n",
      "3 闷开_0 1.4973941\n",
      "4 看_2 0.0\n",
      "5 看_5 0.0\n",
      "6 看_10 0.0\n",
      "7 看_20 0.0\n",
      "8 开_0 -0.0\n",
      "9 丢_0 -0.0\n"
     ]
    }
   ],
   "source": [
    "res = RLModel.sess.run(RLModel.predictions,feed_dict=RLModel._feed_dict(np.array([[[\"A_闷_4\", \"B_看_20\",\"A_闷_4\", \"B_看_20\"], ['diamond_2', 'heart_2', 'spade_2'],\"闷\"]])))\n",
    "for i,v in  zip(RLModel.action_reverse_index_dicts.keys(),res[0]):\n",
    "    print i, RLModel.action_reverse_index_dicts[i],v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.95227855,  1.1853846 ,  0.81203157,  0.95211285, -0.19811791]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RLModel.sess.run(RLModel.predictionsNotSee,feed_dict=RLModel._feed_dict(np.array([[[\"A_闷_4\"], ['diamond_2', 'heart_2', 'spade_2'],\"闷\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RLModel.sess.run(RLModel.playSequenceLengthInput,feed_dict=RLModel._feed_dict(np.array([[[\"A_闷_8\"], ['diamond_1', 'heart_2', 'spade_3'],\"闷\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5002861 , -0.04074519,  0.44523266, -0.11365644,  0.55178744,\n",
       "         0.23713528,  0.4065764 ,  0.37365475,  0.05763792,  0.5122157 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RLModel.sess.run(RLModel.last_output,feed_dict=RLModel._feed_dict(np.array([[[\"A_闷_8\"], ['diamond_1', 'heart_2', 'spade_3'],\"闷\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = RLModel.experience_replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[x[:,2] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
